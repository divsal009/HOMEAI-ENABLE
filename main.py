# -*- coding: utf-8 -*-
"""WEB_HOMEAI_LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/178x9gm_W-QnVZ7fxNtDPiwy-zx9AmvdI

<a href="https://colab.research.google.com/github/divsal009/div/blob/master/HOMEAI_LLM.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""


import nltk
nltk.download('wordnet')

import random
from transformers import pipeline
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles



# Initialize Hugging Face text generation pipeline
generator = pipeline("text2text-generation", model="google/flan-t5-small")

# Track used responses to prevent repetition
used_responses = {
    "open_synonyms": set(),
    "assistive_synonyms": set(),
    "home_adaptation_synonyms": set(),
}

# Function to ensure unique responses
def get_unique_response(response_list, used_set):
    available_responses = [resp for resp in response_list if resp not in used_set]
    if not available_responses:  # If all responses are used, reset the set
        used_set.clear()
        available_responses = response_list
    selected_response = random.choice(available_responses)
    used_set.add(selected_response)
    return selected_response

# Function to generate responses with LLM fallback
def generate_synonym_response(prompt, fallback_responses, used_set):
    try:
        # Generate response dynamically
        output = generator(
            prompt,
            max_length=50,
            num_return_sequences=1
        )
        generated_response = output[0]['generated_text'].strip()
        return generated_response  # Return the LLM response
    except Exception as e:
        print(f"Error generating response with LLM: {e}")
        return get_unique_response(fallback_responses, used_set)  # Fallback if LLM fails

# Function to generate dynamic symptom opening text
def generate_symptom_opening(symptom):
    open_synonyms = list(set([  # Ensure unique responses
        f"Dealing with {symptom} can be challenging, but here are some suggestions to help you manage it.",
        f"Handling {symptom} might be tough, but don't worry, here are some ideas that could help.",
        f"Managing {symptom} can be difficult, but with the right support, things can get easier. Here are some tips.",
        f"Coping with {symptom} can be draining, but I've got some helpful tips to make it more manageable.",
        f"Facing {symptom} is never easy, but with some adjustments, it can become easier. Let’s explore a few options."
    ]))
    prompt = (
        f"Provide a supportive and empathetic sentence for someone dealing with '{symptom}'. "
        f"Make sure the tone is friendly, practical, and similar to these examples:\n"
        f"- {open_synonyms[0]}\n"
        f"- {open_synonyms[1]}"
    )
    llm_response = generate_synonym_response(prompt, open_synonyms, used_responses["open_synonyms"])
    return llm_response

# Function to get dynamic assistive technology text
def get_dynamic_assistive_text(assistive_tech):
    assistive_synonyms = list(set([  # Ensure unique responses
        f"Have you tried using {assistive_tech.lower()}? These can provide great support and help reduce discomfort.",
        f"Consider using {assistive_tech.lower()}. It might help you navigate more easily and reduce the strain.",
        f"Have you thought about trying {assistive_tech.lower()}? It could make daily tasks much easier and more comfortable.",
        f"Perhaps {assistive_tech.lower()} could be the key to enhancing your mobility and offering relief."
    ]))
    prompt = (
        f"Suggest a conversational and practical use for assistive technology like '{assistive_tech}'. "
        f"Make it helpful and similar to these examples:\n"
        f"- {assistive_synonyms[0]}\n"
        f"- {assistive_synonyms[1]}"
    )
    llm_response = generate_synonym_response(prompt, assistive_synonyms, used_responses["assistive_synonyms"])
    return llm_response

# Function to get dynamic home adaptation text
def get_dynamic_home_adaptation_text(home_adaptations):
    home_adaptation_synonyms = list(set([  # Ensure unique responses
        f"At home, small changes like {home_adaptations.lower()} can make a huge difference in how easily you can move around.",
        f"Consider making modifications such as {home_adaptations.lower()}. These adjustments can make your home more comfortable.",
        f"Changing things like {home_adaptations.lower()} at home can make your space more accessible and easier to navigate.",
        f"Home improvements such as {home_adaptations.lower()} can really help make your living space more comfortable and safe."
    ]))
    prompt = (
        f"Provide a practical and supportive suggestion for home adaptations like '{home_adaptations}'. "
        f"Ensure the response is similar to these examples:\n"
        f"- {home_adaptation_synonyms[0]}\n"
        f"- {home_adaptation_synonyms[1]}"
    )
    llm_response = generate_synonym_response(prompt, home_adaptation_synonyms, used_responses["home_adaptation_synonyms"])
    return llm_response

# Commented out IPython magic to ensure Python compatibility.
# %%writefile query_evaluation.py
# from fuzzywuzzy import fuzz
# from nltk.corpus import wordnet
# import re
# 
# # Function to preprocess text
# def preprocess_text(text):
#     return re.sub(r'[^a-zA-Z0-9\s]', '', text.strip().lower()) if text else ""
# 
# # Function to check for exact match
# def exact_match(input_text, target_text):
#     return 1 if preprocess_text(input_text) == preprocess_text(target_text) else 0
# 
# # Function to check for synonym match
# def synonym_match(input_text, target_text):
#     input_text = preprocess_text(input_text)
#     target_text = preprocess_text(target_text)
#     synonyms = set()
#     for syn in wordnet.synsets(target_text):
#         for lemma in syn.lemmas():
#             synonyms.add(preprocess_text(lemma.name()))
#     return 1 if input_text in synonyms else 0
# 
# # Function to calculate fuzzy match score
# def fuzzy_match(input_text, target_text):
#     input_text = preprocess_text(input_text)
#     target_text = preprocess_text(target_text)
#     return fuzz.token_sort_ratio(input_text, target_text) / 100.0
# 
# # Function to calculate query evaluation score
# def query_evaluation(input_text, target_text, weights=None):
#     if weights is None:
#         weights = {'exact': 0.4, 'syn': 0.3, 'fuzzy': 0.3}  # Default weights
#     exact_score = exact_match(input_text, target_text)
#     synonym_score = synonym_match(input_text, target_text)
#     fuzzy_score = fuzzy_match(input_text, target_text)
#     query_score = (weights['exact'] * exact_score +
#                    weights['syn'] * synonym_score +
#                    weights['fuzzy'] * fuzzy_score)
#     return exact_score, synonym_score, fuzzy_score, query_score
#

import os
import pandas as pd
from fuzzywuzzy import fuzz, process
from fastapi import FastAPI, Form
from fastapi.responses import HTMLResponse
from pyngrok import ngrok
import uvicorn
import nest_asyncio
import re
from transformers import pipeline
import nltk
from nltk.corpus import wordnet


import nltk
import random
import os
import requests
import pandas as pd
import re
from fuzzywuzzy import fuzz, process
from fastapi import FastAPI, Form
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from transformers import pipeline
import nest_asyncio
from nltk.corpus import wordnet

# ✅ Download NLP resources
nltk.download('wordnet')
nltk.download('stopwords')

# ✅ Initialize FastAPI app
app = FastAPI()

# ✅ Mount static directory
app.mount("/static", StaticFiles(directory="static"), name="static")


# Apply nest_asyncio for compatibility
nest_asyncio.apply()


# Load the Excel data
#file_path = "/content/DatasetfinaldivyaJan24.xlsx"


# URLs to your dataset files on GitHub
dataset_url = "https://raw.githubusercontent.com/YOUR_GITHUB_USERNAME/YOUR_REPO/main/DatasetfinaldivyaJan24.xlsx"
muscular_url = "https://raw.githubusercontent.com/YOUR_GITHUB_USERNAME/YOUR_REPO/main/Musular_Distrophy27Jan.xlsx"

# Download and save files
def download_file(url, filename):
    response = requests.get(url)
    with open(filename, "wb") as file:
        file.write(response.content)

# Download datasets
download_file(dataset_url, "DatasetfinaldivyaJan24.xlsx")
download_file(muscular_url, "Musular_Distrophy27Jan.xlsx")

# Load data
file_path = "DatasetfinaldivyaJan24.xlsx"
file_path2 = "Musular_Distrophy27Jan.xlsx"

if not os.path.exists(file_path):
    raise FileNotFoundError("The dataset file was not found at the specified path.")

# Read Excel Sheets
excel_data = pd.ExcelFile(file_path)
disease_bodyfn_df = excel_data.parse('30-10-DISEASE VS BODYFN')
bodyfn_assistive_df = excel_data.parse('31-10 BODYFN vs assistive techn')
bodyfn_home_icf_df = excel_data.parse('31-10 BODYFN vs HOME ICF')


# Load the Excel data
#file_path2 = "/content/Musular_Distrophy27Jan.xlsx"
if not os.path.exists(file_path2):
    raise FileNotFoundError("The dataset file was not found at the specified path.")

# Read Excel Sheets
excel_data = pd.ExcelFile(file_path2)

# Parse the sheets into DataFrames
md_activity_part_df = excel_data.parse('Activity_Part')
md_housing_adapt_df = excel_data.parse('HouFac_Adapatn')

# Clean the 'Activity_Part' DataFrame by removing unwanted columns
md_activity_part_df = md_activity_part_df.drop(columns=['Unnamed: 2', 'Unnamed: 3'], errors='ignore')

# Clean the column names in Activity_Part DataFrame
md_activity_part_df.columns = md_activity_part_df.columns.str.strip()

# Clean the 'HouFac_Adapatn' DataFrame by stripping extra spaces
md_housing_adapt_df.columns = md_housing_adapt_df.columns.str.strip()

# Rename columns in 'HouFac_Adapatn' to standardize them
md_housing_adapt_df.rename(columns={
    'HOUSING FACTORS': 'Housing Factors',
    'Housing adaptation': 'Housing Adaptation'
}, inplace=True)

# Ensure that you select the correct columns from the cleaned DataFrame
md_activity_part_df = md_activity_part_df[['Disease', 'Activities and participation limitations', 'Assistive Devices: Technologies']]
md_housing_adapt_df = md_housing_adapt_df[['Disease', 'Housing Factors', 'Housing Adaptation']]




def preprocess_text(text1):
    if not text:
        return ""
    # Normalize text: remove special characters, but retain spaces for compound word detection
    text1 = re.sub(r"[^\w\s]", "", text)  # Keep only alphanumeric and spaces
    text1 = re.sub(r"\s+", " ", text)  # Replace multiple spaces with a single space
    return text1.strip().lower()

# Synonym retrieval function
def get_synonyms(word):
    synonyms = set()
    for syn in wordnet.synsets(word):
        for lemma in syn.lemmas():
            synonym = lemma.name().replace('_', ' ')
            if synonym.lower() != word.lower():
                synonyms.add(synonym)
    return synonyms


# Download NLTK data
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.corpus import stopwords

# # Preprocessing helper function
# def preprocess_text(text):
#     return re.sub(r'[^a-zA-Z0-9\s]', '', text.strip().lower()) if text else ""


def preprocess_text(text):
    if not text:
        return ""
    # Normalize text: remove special characters, but retain spaces for compound word detection
    text = re.sub(r"[^\w\s]", "", text)  # Keep only alphanumeric and spaces
    text = re.sub(r"\s+", " ", text)  # Replace multiple spaces with a single space
    return text.strip().lower()

# Normalize the dataset
disease_bodyfn_df['Disease'] = disease_bodyfn_df['Disease'].apply(preprocess_text)
bodyfn_assistive_df['Symptoms'] = bodyfn_assistive_df['Symptoms'].apply(preprocess_text)
bodyfn_home_icf_df['Symptoms'] = bodyfn_home_icf_df['Symptoms'].apply(preprocess_text)

# Synonym retrieval function
def get_synonyms(word):
    synonyms = set()
    for syn in wordnet.synsets(word):
        for lemma in syn.lemmas():
            synonym = lemma.name().replace('_', ' ')
            if synonym.lower() != word.lower():
                synonyms.add(synonym)
    return synonyms

# Build a precomputed keyword-to-synonym map
def build_keyword_synonym_map(keyword_list):
    synonym_map = {}
    for keyword in keyword_list:
        keyword = preprocess_text(keyword)
        synonym_map[keyword] = get_synonyms(keyword)
    return synonym_map

# Generate the synonym map for all keywords
all_keywords = (
    disease_bodyfn_df['Disease'].tolist()
    + bodyfn_assistive_df['Symptoms'].tolist()
    + bodyfn_home_icf_df['Symptoms'].tolist()
)
all_keywords = [preprocess_text(k) for k in all_keywords]
keyword_synonym_map = build_keyword_synonym_map(all_keywords)

# Fuzzy Matching Helper Function
def find_closest_match(input_text, text_list, threshold=90):
    input_text = preprocess_text(input_text)
    match = process.extractOne(input_text, text_list, scorer=fuzz.token_sort_ratio)
    if match:
        print(f"Attempting to match '{input_text}' - Best match: '{match[0]}' with score: {match[1]}")
    return match[0] if match and match[1] >= threshold else None

def find_contextual_matches(input_text, text_list, threshold=60):
    input_text = preprocess_text(input_text)
    matches = process.extract(input_text, text_list, scorer=fuzz.token_sort_ratio, limit=5)
    return [match[0] for match in matches if match[1] >= threshold]


def extract_keyword(input_text):
    input_text = preprocess_text(input_text)
    if not input_text:
        return None, "No Match"

    tokens = input_text.split()
    compound_phrases = {" ".join(tokens[i:j]) for i in range(len(tokens)) for j in range(i+1, len(tokens)+1)}

    all_keywords = set(
        preprocess_text(keyword)
        for keyword in (
            disease_bodyfn_df["Disease"].tolist()
            + bodyfn_assistive_df["Symptoms"].tolist()
            + bodyfn_home_icf_df["Symptoms"].tolist()
        )
        if isinstance(keyword, str)
    )

    for phrase in compound_phrases:
        if phrase in all_keywords:
            return phrase, "Exact Match"
        for keyword, synonyms in keyword_synonym_map.items():
            if phrase in synonyms or phrase == keyword:
                return keyword, "Synonym Match"

    for phrase in compound_phrases:
        fuzzy_match = find_closest_match(phrase, list(all_keywords))
        if fuzzy_match:
            return fuzzy_match, "Fuzzy Match"

    return None, "No Match"












# Navbar and styles for web interface
def navbar_and_styles():
    return """
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f8ff;
            margin: 0;
            padding: 0;
        }
        .navbar {
            background-color: #004d00;
            padding: 15px;
            text-align: center;
        }
        .navbar a {
            color: white;
            text-decoration: none;
            font-size: 18px;
            margin: 15px;
            font-weight: bold;  /* Makes the link names bold */
        }
        .navbar a:hover {
            text-decoration: underline;
        }
        .container {
            max-width: 800px;
            margin: 50px auto;
            text-align: left;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 10px;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2 {
            color: #004d00;
            margin-bottom: 20px;
        }
        p {
            color: #333;
            font-size: 18px;
            line-height: 1.8;
        }
        input[type="text"] {
            width: 100%;
            padding: 10px;
            font-size: 18px;
            margin: 10px 0;
        }
        button {
            padding: 10px 20px;
            font-size: 18px;
            background-color: #004d00;
            color: white;
            border: none;
            border-radius: 5px;
        }
        button:hover {
            background-color: #003300;
        }
        .result-container {
            padding: 20px;
            background-color: #f9f9f9;
            border-radius: 10px;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
        }
        .result-container h2 {
            color: #004d00;
        }
    </style>
    <div class='navbar'>
        <a href="/">Home</a>
        <a href="/disease">Disease/Symptom Search</a>
        <a href="/muscular_dystrophy">Muscular Dystrophy</a>
        <a href="/contact">Contact Us</a>
    </div>
    """

from fastapi import FastAPI
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles

app = FastAPI()

# Serve static files (images, CSS, etc.) from the /content directory
app.mount("/content", StaticFiles(directory="/content"), name="content")

# Home page route

@app.get("/", response_class=HTMLResponse)
async def home():
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>HOMEAI-ENABLE</title>
        {navbar_and_styles()}
        <style>
            body, html {{
                margin: 0;
                padding: 0;
                height: 100%;
                width: 100%;
                display: flex;
                justify-content: flex-start;
                align-items: flex-start;
                background: url('/static/homaiimage.jpg') no-repeat right bottom;

               # background: url('/content/homaiimage.jpg') no-repeat right bottom;
                background-size: contain; /* Ensure the full image is visible */
                background-position: right bottom; /* Align the image to the bottom right */
                background-attachment: fixed; /* Keeps the image fixed while scrolling */
                text-align: left; /* Ensure text is left aligned */
                padding-top: 60px; /* Create some space between the image and navbar */
            }}

            /* Style for the navbar (green bar) */
            .navbar {{
                padding: 20px;
                background-color: #006400;
                color: white;
                font-weight: bold;
                text-align: center;
                position: fixed;
                width: 100%;
                top: 0;
                left: 0;
                z-index: 10;
            }}

            /* Style for the text content */
            .content {{
                padding: 20px;
                color: darkgreen; /* Dark green text */
                font-weight: bold; /* Bold text */
                font-size: 20px;
                line-height: 1.6;
                max-width: 50%; /* Limit the width of the text */
                margin-top: 20px; /* Add some space above the text */
                word-wrap: break-word; /* Allow the text to wrap */
                white-space: normal; /* Allow text to wrap across multiple lines */
            }}

            h1 {{
                text-align: center;
                font-size: 36px;
            }}

            /* Make sure only 3 words per line */
            .content p {{
                width: 60%; /* Restrict the width of the text block to 60% */
                display: inline-block;
            }}
        </style>
    </head>
    <body>
        <div class="navbar">
            <a href="/" style="color: white; text-decoration: none;">Home</a>
            <a href="/disease" style="color: white; text-decoration: none;">Disease/Symptom Search</a>
            <a href="/muscular_dystrophy" style="color: white; text-decoration: none;">Muscular Dystrophy</a>
            <a href="/contact" style="color: white; text-decoration: none;">Contact Us</a>
        </div>

        <div class="content">
            <h1 style="text-align: left;">HOMEAI-ENABLE</h1>

            <p>Your trusted platform for insights into diseases, symptoms, assistive technologies, and personalized home adaptations.</p>
            <p>Start by entering a disease or symptom, and let us guide you toward solutions that enhance your well-being.</p>
        </div>
    </body>
    </html>
    """

@app.get("/disease", response_class=HTMLResponse)
async def disease_get():
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Disease Search</title>
        {navbar_and_styles()}
    </head>
    <body>
        <div class="container">
            <h1>Search for Diseases or Symptoms</h1>
            <form method="post" action="/disease">
                <input type="text" name="disease_name" placeholder="Enter a disease or symptom" required>
                <button type="submit" style="margin-top: 15px;">Search</button>
            </form>
        </div>
    </body>
    </html>
    """

import pandas as pd
def calculate_qma_score(queries):
    total_score = 0
    total_weight = 0
    table_data = []

    # Define accurate weights and accuracy values for match types
    match_type_weights = {
        "Exact Match": 0.5,
        "Synonym Match": 0.3,
        "Fuzzy Match": 0.2
    }
    match_type_accuracies = {
        "Exact Match": 97.5,
        "Synonym Match": 91.43,
        "Fuzzy Match": 88.0
    }

    for query in queries:
        match_type = query.get("match_type", "No Match")
        weight = match_type_weights.get(match_type, 0.0)  # Default to 0 if match type is unknown
        accuracy = match_type_accuracies.get(match_type, 0.0)  # Default to 0 if match type is unknown

        weighted_contribution = round(weight * accuracy, 2)
        table_data.append({
            "Query": query.get("query", ""),
            "Match Type": match_type,
            "Weight": weight,
            "Accuracy": accuracy,
            "Weighted Contribution": weighted_contribution
        })

        total_weight += weight
        total_score += weighted_contribution

    qma_score = round(total_score / total_weight, 2) if total_weight > 0 else 0

    # Prepare the results table as a pandas DataFrame
    import pandas as pd
    qma_table = pd.DataFrame(table_data)

    return {
        "QMA Score": qma_score,
        "Detailed Table": qma_table
    }









@app.post("/disease", response_class=HTMLResponse)
async def disease_post(disease_name: str = Form(...)):
    keyword, match_type = extract_keyword(disease_name)  # Ensure extract_keyword returns both keyword and match_type
    response = navbar_and_styles()

    # Add custom CSS specific to this page (retained)
    response += """
    <style>
        /* fonting */
        body {
            font-family: 'Arial', sans-serif;
            background-color: #f0f8ff;
            margin: 0;
            padding: 0;
        }

        /* Navbar styling */
        .navbar {
            background-color: #004d00;
            padding: 10px 20px;
            text-align: center;
        }

        .navbar a {
            color: white;
            text-decoration: none;
            font-size: 16px;
            margin: 10px 15px;
            font-weight: bold;
        }

        .navbar a:hover {
            text-decoration: underline;
        }

        /* Container styling */
        .container {
            max-width: 900px;
            margin: 20px auto;
            text-align: left;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 10px;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
        }

        /* Title styling */
        h1, h2 {
            color: #004d00;
            margin-bottom: 15px;
            font-weight: 600;
            font-size: 24px;
        }

        /* Paragraph styling */
        p {
            color: #333;
            font-size: 16px;
            line-height: 1.6;
            margin-bottom: 10px;
        }

        /* List styling */
        ul {
            padding-left: 20px;
            margin: 0;
        }

        ul li {
            margin-bottom: 8px;
            font-size: 16px;
        }

        /* Button styling */
        button {
            padding: 10px 20px;
            font-size: 16px;
            background-color: #004d00;
            color: white;
            border: none;
            border-radius: 5px;
            width: 100%;
            margin-top: 10px;
        }

        button:hover {
            background-color: #003300;
        }

        /* Result container styling */
        # .result-container {
        #     padding: 15px;
        #     background-color: #f9f9f9;
        #     border-radius: 10px;
        #     box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
        #     margin-top: 10px;
        # }
        .result-container {
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 10px;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
            margin-top: 10px;
            text-align: justify; /* Ensures justified alignment */
            font-family: Arial, sans-serif; /* Consistent font style */
            font-size: 16px; /* Readable font size */
            line-height: 1.6; /* Improve spacing between lines */
            color: #333; /* Neutral text color */
        }


        .result-container h2 {
            color: #003300;
            font-size: 20px;
        }
    </style>
    """

    response += "<div class='container'>"

    if not keyword:
        response += f"""
        <h1 style='font-size: 20px;'>I'm sorry, I couldn’t find anything for '{disease_name}'.</h1>
        <p>Maybe try rephrasing it, or tell me a bit more? I’m here to help!</p>
        </div>
        """
        return HTMLResponse(content=response)






    # Automatically match against diseases and symptoms
    matched_disease = find_closest_match(keyword, disease_bodyfn_df['Disease'].tolist())
    matched_symptom = find_closest_match(keyword, bodyfn_assistive_df['Symptoms'].tolist() + bodyfn_home_icf_df['Symptoms'].tolist())

    if matched_disease:
        disease_info = disease_bodyfn_df[disease_bodyfn_df['Disease'] == matched_disease]
        symptoms = disease_info['Symptoms'].values[0].split(", ") if not disease_info.empty else []

        # First, display the disease-related sentence
        response += f"<h1>Here’s what I found about <strong>{matched_disease.capitalize()}</strong>:</h1>"

        # Second, list the symptoms
        response += f"<p>Symptoms include: {', '.join(symptoms)}.</p>"

        # Third, display the opening sentence with suggestions
        opening_sentence = generate_symptom_opening(", ".join(symptoms))
        response += f"<p>{opening_sentence}</p>"

        for symptom in symptoms:
            # Automatically gather assistive technology and home adaptation information
            assistive_tech = "No assistive technology available"
            home_adaptations = "No home adaptations available"

            tech_info = bodyfn_assistive_df[bodyfn_assistive_df['Symptoms'] == preprocess_text(symptom)]
            home_info = bodyfn_home_icf_df[bodyfn_home_icf_df['Symptoms'] == preprocess_text(symptom)]

            if not tech_info.empty:
                assistive_tech = tech_info['Assistive Technology'].values[0]
            if not home_info.empty:
                home_adaptations = ", ".join(home_info['Home functions'].dropna().tolist())

            # Generate varied symptom opening and suggestions for assistive tech and home adaptations
            assistive_tech_text = get_dynamic_assistive_text(assistive_tech)
            home_adaptations_text = get_dynamic_home_adaptation_text(home_adaptations)

            response += f"""
            <div class='result-container'>
                <h2>Symptom: <strong>{symptom.capitalize()}</strong></h2>
                <ul>
                    <li><strong>Assistive Technologies:</strong> {assistive_tech_text}</li>
                    <li><strong>Home Adaptations:</strong> {home_adaptations_text}</li>
                </ul>
            </div>
            """

    if matched_symptom:
        # Handle symptoms independently
        assistive_info = bodyfn_assistive_df[bodyfn_assistive_df['Symptoms'] == matched_symptom]
        home_info = bodyfn_home_icf_df[bodyfn_home_icf_df['Symptoms'] == matched_symptom]

        assistive_tech = assistive_info['Assistive Technology'].values[0] if not assistive_info.empty else "No assistive technology available"
        home_adaptations = ", ".join(home_info['Home functions'].dropna().tolist()) if not home_info.empty else "No home adaptations available"

        # Generate varied symptom opening and suggestions for assistive tech and home adaptations
        opening_sentence = generate_symptom_opening(matched_symptom)
        assistive_tech_text = get_dynamic_assistive_text(assistive_tech)
        home_adaptations_text = get_dynamic_home_adaptation_text(home_adaptations)

        response += f"""
        <div class='result-container'>
            <h2>Symptom: <strong>{matched_symptom.capitalize()}</strong></h2>
            <p>{opening_sentence}</p>
            <ul>
                <li><strong>Assistive Technologies:</strong> {assistive_tech_text}</li>
                <li><strong>Home Adaptations:</strong> {home_adaptations_text}</li>
            </ul>
        </div>
        """

    if not matched_disease and not matched_symptom:
        # Handle cases where no match is found
        response += f"""
        <h1 style='font-size: 20px;'>No relevant information found for '{disease_name}'.</h1>
        <p>Please try rephrasing your input, or ask for general assistance. I’m here to help!</p>
        """
        return HTMLResponse(content=response)

    # Prepare query details for QMA calculation
    accuracy_scores = {
        "Exact Match": 97.5,
        "Synonym Match": 91.43,
        "Fuzzy Match": 88.0,
    }
    accuracy = accuracy_scores.get(match_type, 0)

    queries = [{"query": disease_name, "match_type": match_type, "accuracy": accuracy}]

    # Calculate QMA score
    qma_result = calculate_qma_score(queries)
    qma_score = qma_result["QMA Score"]
    qma_table = qma_result["Detailed Table"]

    # Print QMA table in Colab console
    print("\nQMA Score Calculation:")
    print(qma_table)

    # Closing statement
    response += "<p>If you need further assistance or more suggestions, feel free to reach out. I’m here to help!</p>"


# NHS Official Page link (dynamically generated)
    nhs_link = f"https://www.nhs.uk/conditions/{matched_disease.replace(' ', '-').lower()}/"

    response += f"""

    <p style="font-size: inherit; font-weight: inherit; color: inherit;">
    For more trusted medical information about
    <strong style="color: red;">{matched_disease.capitalize()}</strong>, visit:
    <strong><a href="https://www.nhs.uk/conditions/{matched_disease.replace(' ', '-').lower()}/"
    target="_blank" class="learn-more" style="font-size: inherit; font-weight: inherit; color: inherit;">
    NHS Official Page</a></strong>
    </p>
    """



    response += "</div>"


    return HTMLResponse(content=response)

@app.post("/search1", response_class=HTMLResponse)
async def search1(activity_input: str = Form(...), search_type: str = Form(...)):
    def preprocess_text(text):
        """Normalize text: remove special characters, handle spaces, and make lowercase."""
        if not text:
            return ""
        text = re.sub(r"[^\w\s]", "", text)  # Remove special characters
        text = re.sub(r"\s+", " ", text)    # Normalize spaces
        return text.strip().lower()        # Convert to lowercase

    def extract_keywords(sentence):
        """Extract meaningful keywords or phrases."""
        normalized = preprocess_text(sentence)
        words = normalized.split()

        # Generate n-grams (1 to 3 words)
        ngrams = set()
        for n in range(1, 4):  # Extract 1-word, 2-word, and 3-word combinations
            for i in range(len(words) - n + 1):
                ngram = " ".join(words[i:i + n])
                ngrams.add(ngram)

        return list(ngrams)  # Return a list of keywords/phrases

    # Extract keywords from the input
    keywords = extract_keywords(activity_input)

    # Debugging: Log extracted keywords
    print(f"Extracted Keywords: {keywords}")

    # Initialize response
    response = f"<h2>Results for '{activity_input}'</h2>"

    if not keywords:
        return f"<h2>Please enter a valid query.</h2>"

    if search_type == 'assistive_technology':
        # Find matches for assistive technology
        matches = []
        for keyword in keywords:
            match = md_activity_part_df[
                md_activity_part_df['Activities and participation limitations']
                .str.contains(fr"\b{keyword}\b", case=False, na=False)  # Word-boundary matching
            ]
            matches.append(match)

        # Consolidate all matches and remove duplicates
        combined_matches = pd.concat(matches).drop_duplicates()

        # Strict relevance filtering
        relevant_matches = combined_matches[
            combined_matches['Activities and participation limitations'].apply(
                lambda x: any(preprocess_text(keyword) in preprocess_text(x) for keyword in keywords)
            )
        ]

        if not relevant_matches.empty:
            response += "<h2>Matching Activities and Assistive Devices:</h2><ul>"
            for _, row in relevant_matches.iterrows():
                activity = row['Activities and participation limitations']
                assistive_device = row['Assistive Devices: Technologies']
                response += f"<li><strong>{activity}:</strong> {assistive_device}</li>"
            response += "</ul>"
        else:
            response += f"<h2>No matching activities found for '{activity_input}'.</h2>"

    elif search_type == 'housing_adaptation':
        # Find matches for housing adaptation
        matches = []
        for keyword in keywords:
            match = md_housing_adapt_df[
                md_housing_adapt_df['Housing Factors']
                .str.contains(fr"\b{keyword}\b", case=False, na=False)  # Word-boundary matching
            ]
            matches.append(match)

        # Consolidate all matches and remove duplicates
        combined_matches = pd.concat(matches).drop_duplicates()

        # Strict relevance filtering
        relevant_matches = combined_matches[
            combined_matches['Housing Factors'].apply(
                lambda x: any(preprocess_text(keyword) in preprocess_text(x) for keyword in keywords)
            )
        ]

        if not relevant_matches.empty:
            response += "<h2>Matching Housing Factors and Adaptations:</h2><ul>"
            for _, row in relevant_matches.iterrows():
                housing_factor = row['Housing Factors']
                housing_adaptation = row['Housing Adaptation']
                response += f"<li><strong>{housing_factor}:</strong> {housing_adaptation}</li>"
            response += "</ul>"
        else:
            response += f"<h2>No matching housing factors found for '{activity_input}'.</h2>"

    else:
        response += f"<h2>Invalid search type: '{search_type}'.</h2>"

    return HTMLResponse(content=response)







@app.get("/muscular_dystrophy", response_class=HTMLResponse)
async def muscular_dystrophy():
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Muscular Dystrophy</title>
        {navbar_and_styles()}
        <style>
            /* Removed background color and font style here since navbar_and_styles() will handle them */
            .container {{
                display: flex;
                flex-direction: row;
                justify-content: center;         /* Centers the two columns horizontally */
                align-items: flex-start;         /* Aligns items to the top */
                padding: 20px;
                background: #fff;
                border-radius: 8px;
                box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
                max-width: 100%;
                margin: 50px auto;
            }}
            .left-column, .right-column {{
                flex: 1;
                padding: 20px;
                background-color: #fff;
                max-width: 50%;
                border-radius: 8px;
                box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
                text-align: center;
            }}
            h1, h2 {{
                color: #006400;
                text-align: center;
            }}
            p {{
                color: #333;
                font-size: 16px;
                text-align: center;
                max-width: 80%;
                margin: 0 auto;
            }}
            .input-container {{
                margin-bottom: 20px;
                text-align: center;
            }}
            .input-container input[type="text"] {{
                padding: 10px;
                width: 80%;
                border: 1px solid #ccc;
                border-radius: 4px;
            }}
            button {{
                padding: 8px 16px;
                background-color: green;
                color: white;
                border: none;
                border-radius: 4px;
                cursor: pointer;
                margin-top: 10px;
                width: auto;
            }}
            button:hover {{
                background-color: darkgreen;
            }}
            #activities_output, #housing_output {{
                text-align: justify;
                margin: 20px;
                padding: 10px;
                background-color: #f1f1f1;
                border-radius: 8px;
                box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
            }}
        </style>
    </head>
    <body>

        <div class="container">
            <div class="left-column">
                <h1>Muscular Dystrophy Overview</h1>
                <p>Muscular dystrophy refers to a group of inherited disorders that cause progressive muscle weakness and degeneration.</p>

                <h2>Enter Activities and Participation Limitations:</h2>
                <div class="input-container">
                    <input type="text" id="activities_limitations" placeholder="Enter activities and participation limitations" />
                    <button onclick="searchAssistiveDevices()">Assistive Technologies</button>
                </div>

                <h2>Enter Housing Factors:</h2>
                <div class="input-container">
                    <input type="text" id="housing" placeholder="Enter housing factors" />
                    <button onclick="searchHousing()">Housing Adaptation</button>
                </div>
            </div>

            <div class="right-column">
                <div id="activities_output"></div>
                <div id="housing_output"></div>
            </div>
        </div>

        <script>
            function searchAssistiveDevices() {{
                var inputText = document.getElementById("activities_limitations").value;
                // Clear previous output
                document.getElementById("activities_output").innerHTML = '';
                fetch('/search1', {{
                    method: 'POST',
                    headers: {{ 'Content-Type': 'application/x-www-form-urlencoded' }},
                    body: 'activity_input=' + encodeURIComponent(inputText) + '&search_type=assistive_technology'
                }}).then(response => response.text())
                  .then(data => document.getElementById("activities_output").innerHTML = data);
            }}

            function searchHousing() {{
                var inputText = document.getElementById("housing").value;
                // Clear previous output
                document.getElementById("housing_output").innerHTML = '';
                fetch('/search1', {{
                    method: 'POST',
                    headers: {{ 'Content-Type': 'application/x-www-form-urlencoded' }},
                    body: 'activity_input=' + encodeURIComponent(inputText) + '&search_type=housing_adaptation'
                }}).then(response => response.text())
                  .then(data => document.getElementById("housing_output").innerHTML = data);
            }}
        </script>
    </body>
    </html>
    """


@app.get("/contact", response_class=HTMLResponse)
async def contact():
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Contact Us</title>
        {navbar_and_styles()}  <!-- Navbar with styles -->
    </head>
    <body>
        <div class="container">
            <h1>Contact Us</h1>
            <p>If you have any questions or feedback, feel free to reach out to us!</p>
            <p>Email: contact@homeai-enable.com</p>
            <p>Phone: +44 7442685644</p>
        </div>
    </body>
    </html>
    """




# Finally, the line where the FastAPI server is run:
public_url = ngrok.connect(8000)
print(f"Public URL: {public_url}")
uvicorn.run(app, host="127.0.0.1", port=8000)


